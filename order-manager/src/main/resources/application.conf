akka {
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    loglevel = "INFO"
    stdout-loglevel = "INFO"

    actor {
        // Required until https://github.com/akka/akka/pull/28333 is available
        allow-java-serialization = on
        debug {
          receive = on // log all messages sent to an actor if that actors receive method is a LoggingReceive
          autoreceive = off // log all special messages like Kill, PoisoffPill etc sent to all actors
          lifecycle = off // log all actor lifecycle events of all actors
          fsm = off // enable logging of all events, transitioffs and timers of FSM Actors that extend LoggingFSM
          event-stream = off // enable logging of subscriptions (subscribe/unsubscribe) on the ActorSystem.eventStream
        }
    }

    routes {
      # If ask takes more time than this to complete the request is failed
      ask-timeout = 5s
    }
    persistence {
        journal {
          plugin = "jdbc-journal"
          auto-start-journals = ["jdbc-journal"]
        }
        snapshot-store {
          plugin = "jdbc-snapshot-store"
          auto-start-journals = ["jdbc-snapshot-store"]
        }
        max-concurrent-recoveries = 50
      }
}

order-manager-dispatcher {
    mailbox-type = org.mediamarktsaturn.order.order.actor.OrderManagerMailbox
}

docker {
  host = localhost
}

akka-persistence-jdbc {
  logicalDeletion.enable = false
  tagSeparator = ","
  database-provider-fqcn = "akka.persistence.jdbc.db.DefaultSlickDatabaseProvider"
  shared-databases {
    slick {
      profile = "slick.jdbc.MySQLProfile$"
      dataSourceClass = "slick.jdbc.DatabaseUrlDataSource"
      db {
        host = ${docker.host}
        port = "3306"
        url = "jdbc:mysql://localhost:3306/mysql?cachePrepStmts=true&cacheCallableStmts=true&cacheServerConfiguration=true&useLocalSessionState=true&elideSetAutoCommits=true&alwaysSendSetIsolation=false&enableQueryTimeouts=false&connectionAttributes=none&verifyServerCertificate=false&useSSL=false&allowPublicKeyRetrieval=true&useUnicode=true&useLegacyDatetimeCode=false&serverTimezone=UTC&rewriteBatchedStatements=true"
        user = "root"
        password = "root"
        driver = "com.mysql.cj.jdbc.Driver"
        numThreads = 5
        maxConnections = 5
        minConnections = 1
        idleTimeout = 10000 // 10 seconds
      }
    }
  }
}

jdbc-journal {
    class = "akka.persistence.jdbc.journal.JdbcAsyncWriteJournal"
    logicalDelete = ${akka-persistence-jdbc.logicalDeletion.enable}
    tagSeparator = ${akka-persistence-jdbc.tagSeparator}
    dao = "akka.persistence.jdbc.journal.dao.ByteArrayJournalDao"
    # The size of the buffer used when queueing up events for batch writing. This number must be bigger then the number
    # of events that may be written concurrently. In other words this number must be bigger than the number of persistent
    # actors that are actively peristing at the same time.
    bufferSize = 1000
    # The maximum size of the batches in which journal rows will be inserted
    batchSize = 400
    # The maximum size of the batches in which journal rows will be read when recovering
    replayBatchSize = 400
    # The maximum number of batch-inserts that may be running concurrently
    parallelism = 8
    use-shared-db = "slick"
    tables {
        journal {
          tableName = "journal"
          schemaName = ""
          columnNames {
            ordering = "ordering"
            deleted = "deleted"
            persistenceId = "persistence_id"
            sequenceNumber = "sequence_number"
            created = "created"
            tags = "tags"
            message = "message"
          }
        }
      }
}

# the akka-persistence-snapshot-store in use
jdbc-snapshot-store {
    use-shared-db = "slick"
    class = "akka.persistence.jdbc.snapshot.JdbcSnapshotStore"
    dao = "akka.persistence.jdbc.snapshot.dao.ByteArraySnapshotDao"
    tables {
        snapshot {
          tableName = "snapshot"
          schemaName = ""
          columnNames {
            persistenceId = "persistence_id"
            sequenceNumber = "sequence_number"
            created = "created"
            snapshot = "snapshot"
          }
        }
    }
}

# the akka-persistence-query provider in use
jdbc-read-journal {
class = "akka.persistence.jdbc.query.JdbcReadJournalProvider"
dao = "akka.persistence.jdbc.query.dao.ByteArrayReadJournalDao"
write-plugin = "jdbc-journal"
includeLogicallyDeleted = ${akka-persistence-jdbc.logicalDeletion.enable}
# New events are retrieved (polled) with this interval.
refresh-interval = "1s"
# How many events to fetch in one query (replay) and keep buffered until they are delivered downstreams.
max-buffer-size = "500"
use-shared-db = "slick"
# If enabled, automatically close the database connection when the actor system is terminated
add-shutdown-hook = true
tagSeparator = ${akka-persistence-jdbc.tagSeparator}
tables {
    journal {
      tableName = "journal"
      schemaName = ""
      columnNames {
        ordering = "ordering"
        persistenceId = "persistence_id"
        sequenceNumber = "sequence_number"
        created = "created"
        tags = "tags"
        message = "message"
      }
    }
  }
}